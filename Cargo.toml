[package]
name = "caret"
version = "0.4.0"
edition = "2021"
description = "A blazingly fast TUI for inspecting and curating LLM training datasets"
authors = ["Caret Contributors"]
license = "MIT"
readme = "README.md"
repository = "https://github.com/rayanouaddi/caret"
homepage = "https://github.com/rayanouaddi/caret"
keywords = ["tui", "llm", "dataset", "tokenizer", "ai"]
categories = ["command-line-utilities", "development-tools"]

[dependencies]
ratatui = "0.29.0"
crossterm = "0.28.0"
memmap2 = "0.9.0"
tokenizers = { version = "0.20.0", features = ["http"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
argh = "0.1.13"
anyhow = "1.0"
regex = "1.10"
lru = "0.12"

# Concurrent deduplication engine
rayon = "1.10"

# Multi-format support
parquet = { version = "54", default-features = false, features = ["arrow", "snap", "zstd", "lz4", "async"] }
arrow = { version = "54", default-features = false, features = ["json"] }
csv = "1.3"

# Modern tokenizer (Tiktoken with cl100k_base)
tiktoken-rs = "0.6"

# Async runtime & networking (MCP server + HF streaming)
tokio = { version = "1", features = ["full"] }
axum = { version = "0.8", features = ["json"] }
reqwest = { version = "0.12", default-features = false, features = ["rustls-tls", "json", "stream"] }
futures = "0.3"
bytes = "1"
tower = "0.5"
tower-http = { version = "0.6", features = ["cors", "trace"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

[profile.release]
lto = true
strip = true
codegen-units = 1
panic = "abort"
opt-level = 3

[dev-dependencies]
tempfile = "3.24.0"
