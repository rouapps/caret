# ğŸš€ Caret

<p align="center">
  <b>Blazingly fast TUI for inspecting and curating LLM training datasets</b>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/rust-1.75+-orange.svg" alt="Rust 1.75+">
  <img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="MIT License">
  <img src="https://img.shields.io/badge/platform-linux%20%7C%20macos%20%7C%20windows-lightgrey.svg" alt="Platform">
</p>

---

Open 50GB+ datasets **instantly**. Visualize token boundaries. Catch data quality issues before they kill your fine-tuning run.

## âœ¨ Features

### ğŸ“ Instant File Opening
Memory-mapped I/O means your 100GB dataset opens in **0.1 seconds**. No loading bars. No "file too large" errors.

### ğŸ”¬ Token X-Ray Mode
Press `Tab` to see exactly how your text tokenizes. Alternating background colors show token boundaries - spot tokenization issues instantly.

### ğŸ§  Reasoning Linter  
Built for Chain-of-Thought datasets. Automatically detects:
- Unbalanced `<think>`/`</think>` tags
- Invalid JSON/JSONL structure  
- Missing required keys

### ğŸ”§ Auto-Fix Mode (NEW)
Automatically repair common dataset issues:
```bash
caret data.jsonl --fix              # Creates data_fixed.jsonl
caret data.jsonl --fix -o clean.jsonl  # Custom output path
```

### ğŸ“ Detail Panel
Press `Enter` to open a split-screen view with pretty-printed JSON. Navigate deep nested structures without squinting at minified data.

### ğŸ”— Pipeline Support
Fully compatible with Unix pipelines:
```bash
cat huge_dataset.jsonl | caret -
curl https://example.com/data.jsonl | caret -
```

## ğŸš€ Quick Start

```bash
# Install from source
cargo install --path .

# Open a dataset
caret your_dataset.jsonl

# With linter
caret your_dataset.jsonl --lint

# With tokenizer (Token X-Ray mode)
caret your_dataset.jsonl --tokenizer path/to/tokenizer.json
```

## âŒ¨ï¸ Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `j` / `â†“` | Move down |
| `k` / `â†‘` | Move up |
| `g` | Go to top |
| `G` | Go to bottom |
| `Ctrl+d` | Page down |
| `Ctrl+u` | Page up |
| `Tab` | Cycle view: TEXT â†’ TOKEN X-RAY â†’ TREE |
| `Enter` | Toggle detail panel (pretty JSON) |
| `?` | Show help |
| `q` | Quit |

## ğŸ“¦ Installation

### From Source (Recommended)

```bash
git clone https://github.com/yourusername/caret
cd caret
cargo build --release
./target/release/caret --help
```

### Requirements
- Rust 1.75+
- A terminal with 256-color support

## ğŸ”§ Usage

```bash
# Basic usage
caret data.jsonl

# Enable linting
caret data.jsonl --lint

# Lint with required keys check
caret data.jsonl --lint --required-keys "messages,prompt"

# Token visualization (requires tokenizer.json)
caret data.jsonl --tokenizer ./llama3-tokenizer.json

# Pipeline mode (read from stdin)
cat data.jsonl | caret -

# Auto-fix mode (headless, creates new file)
caret data.jsonl --fix                 # â†’ data_fixed.jsonl
caret data.jsonl --fix -o output.jsonl # Custom output
caret data.jsonl --fix --fix-in-place  # Overwrite original (careful!)
caret data.jsonl --fix --skip-invalid  # Skip unfixable lines
```

## ğŸ¯ Why Caret?

Fine-tuning LLMs is brutally unforgiving. A single malformed JSON line or unbalanced reasoning tag can tank your training run and waste thousands of dollars in compute.

**Caret catches these issues before they cost you:**

| Problem | VS Code | jq | Caret |
|---------|---------|----|---------| 
| Open 10GB file | âŒ Crashes | âœ… Slow | âœ… Instant |
| See token boundaries | âŒ | âŒ | âœ… |
| Find broken `<think>` tags | Manual | âŒ | âœ… Auto |
| Smooth scrolling | âŒ | âŒ | âœ… 60 FPS |

## ğŸ“ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Caret TUI                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Dataset  â”‚  â”‚Tokenizer â”‚  â”‚    Linter        â”‚   â”‚
â”‚  â”‚  (mmap)  â”‚  â”‚ (HF Rust)â”‚  â”‚ (Regex + JSON)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Ratatui + Crossterm                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Memory Mapping**: Zero-copy file access via `memmap2`
- **Line Indexing**: O(1) access to any line in the file
- **Tokenization**: Native Rust bindings to HuggingFace tokenizers
- **Rendering**: Immediate-mode TUI with 60 FPS scrolling

## ğŸ¤ Contributing

Contributions welcome! Check out the issues labeled `good first issue`.

```bash
# Run in development mode
cargo run -- test_data.jsonl

# Run tests
cargo test

# Build optimized release
cargo build --release
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

<p align="center">
  Built with ğŸ¦€ Rust and â¤ï¸ for the LLM community
</p>
# caret
